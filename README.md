# IngestÃ£o e Busca SemÃ¢ntica com LangChain e Postgres

## ğŸ¯ Funcionalidades
- **IngestÃ£o**: Processar arquivos PDF e armazenar em banco vetorial PostgreSQL
- **Chat**: Interface CLI para perguntas baseadas exclusivamente no conteÃºdo do PDF
- **Chat com histÃ³rico**: Interface CLI para perguntas baseadas exclusivamente no conteÃºdo do PDF e com histÃ³rico de conversaÃ§Ã£o.

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ docker-compose.yml         # ConfiguraÃ§Ã£o PostgreSQL + pgVector
â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â”œâ”€â”€ .env.example              # Template de variÃ¡veis de ambiente
â”œâ”€â”€ libs/
â”‚   â””â”€â”€ envs/
â”‚       â””â”€â”€ env_validator.py  # Validador interativo de variÃ¡veis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py            # Script de ingestÃ£o do PDF
â”‚   â”œâ”€â”€ search.py            # Script de busca semÃ¢ntica
â”‚   â”œâ”€â”€ chat.py              # Interface CLI interativa
â”‚   â””â”€â”€ chat_with_history.py # Interface CLI interativa com histÃ³rico de conversaÃ§Ã£o
â”œâ”€â”€ document.pdf             # PDF de exemplo para ingestÃ£o
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ› ï¸ Tecnologias
- **Python 3.10+** com tipagem
- **LangChain** para processamento de documentos
- **PostgreSQL + pgVector** para armazenamento vetorial
- **Google Gemini** para embeddings e geraÃ§Ã£o de respostas
- **Docker Compose** para infraestrutura

## PrÃ©-requisitos
- Python 3.10+
- Docker e Docker Compose
- Chave de API do Google Gemini

## ConfiguraÃ§Ã£o

### 1. Ambiente Virtual
Crie e ative um ambiente virtual:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. DependÃªncias
Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

### 3. VariÃ¡veis de Ambiente
Copie o arquivo `.env.example` para `.env` e preencha as variÃ¡veis:
```bash
cp .env.example .env
```

Edite o arquivo `.env`:
```env
GOOGLE_API_KEY=your_google_api_key_here
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag
PG_VECTOR_COLLECTION_NAME=pdf_chunks
PDF_PATH=document.pdf
```

**Importante**: Substitua `your_google_api_key_here` pela sua chave de API do Google Gemini.

## Ordem de ExecuÃ§Ã£o

### 1. Subir o banco de dados:
```bash
docker compose up -d
```

### 2. Executar ingestÃ£o do PDF:
```bash
python src/ingest.py
```

### 3. Rodar o chat:
```bash
python3 src/chat.py
```

### 4. Rodar o chat com histÃ³rico:
```bash
python3 src/chat_with_history.py
```

## ğŸ’¬ Como Usar o CLI

### Interface do Chat
O sistema oferece uma interface de linha de comando interativa:

```
ğŸ” Validando variÃ¡veis de ambiente...
ğŸ“‹ VariÃ¡veis configuradas:
  âœ… GOOGLE_API_KEY = AIzaSyAU...
  âœ… DATABASE_URL = postgresql+psycopg://postgres:postgres@localhost:5432/rag
  âœ… PG_VECTOR_COLLECTION_NAME = pdf_chunks
  âœ… PDF_PATH = document.pdf
âœ… Todas as variÃ¡veis de ambiente estÃ£o configuradas!

FaÃ§a sua pergunta (digite 'sair' para encerrar):

PERGUNTA DO USUÃRIO: me fala sobre o documento
RESPOSTA DO MODEL: O documento contÃ©m uma lista de empresas, seus respectivos setores de atuaÃ§Ã£o, receita (em reais) e ano de fundaÃ§Ã£o. As empresas estÃ£o agrupadas por nomes que comeÃ§am com "Ã‰pico", "Ãmpar", "TrÃ­ade", "Vale", "GrÃ£o", "AlianÃ§a", "Esmeralda" e "Cobalto".

PERGUNTA DO USUÃRIO: qual empresa tem maior receita?
RESPOSTA DO MODEL: [Resposta baseada no conteÃºdo do PDF]

PERGUNTA DO USUÃRIO: qual Ã© a capital da FranÃ§a?
RESPOSTA DO MODEL: NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.

PERGUNTA DO USUÃRIO: sair
Encerrando chat.
```

### Comandos DisponÃ­veis
- **Qualquer pergunta**: O sistema busca no conteÃºdo do PDF e responde
- **`sair`**, **`exit`**, **`quit`**: Encerra o chat

## âš™ï¸ Requisitos do Projeto

### ğŸ“„ IngestÃ£o do PDF
- **Chunking**: PDF dividido em pedaÃ§os de 1000 caracteres com sobreposiÃ§Ã£o de 150
- **Embeddings**: Cada chunk convertido em vetor usando `models/embedding-001` do Gemini
- **Armazenamento**: Vetores salvos no PostgreSQL com extensÃ£o pgVector

### ğŸ” Busca SemÃ¢ntica
- **Interface CLI**: Chat interativo no terminal
- **Busca vetorial**: Encontra os 10 chunks mais relevantes (k=10)
- **GeraÃ§Ã£o de resposta**: LLM Gemini processa contexto e responde
- **ValidaÃ§Ã£o de contexto**: Responde apenas com base no PDF ingerido


## ğŸ”§ Detalhes TÃ©cnicos

### Prompt Template Chat
O sistema utiliza o template disponibilizado pelo LangChain para garantir respostas baseadas apenas no contexto:

```python
PROMPT_TEMPLATE = """
CONTEXTO:
{contexto}

REGRAS:
- Responda somente com base no CONTEXTO.
- Se a informaÃ§Ã£o nÃ£o estiver explicitamente no CONTEXTO, responda:
  "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta."
- Nunca invente ou use conhecimento externo.
- Nunca produza opiniÃµes ou interpretaÃ§Ãµes alÃ©m do que estÃ¡ escrito.

EXEMPLOS DE PERGUNTAS FORA DO CONTEXTO:
Pergunta: "Qual Ã© a capital da FranÃ§a?"
Resposta: "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta."

Pergunta: "Quantos clientes temos em 2024?"
Resposta: "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta."

Pergunta: "VocÃª acha isso bom ou ruim?"
Resposta: "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta."

PERGUNTA DO USUÃRIO:
{pergunta}

RESPONDA A "PERGUNTA DO USUÃRIO"
"""
```

### Fluxo de Dados
1. **PDF â†’ Chunks**: Documento dividido em pedaÃ§os de 1000 caracteres
2. **Chunks â†’ Embeddings**: VetorizaÃ§Ã£o usando Gemini embeddings
3. **Embeddings â†’ PostgreSQL**: Armazenamento com pgVector
4. **Query â†’ Busca**: Similaridade semÃ¢ntica nos vetores
5. **Contexto â†’ LLM**: GeraÃ§Ã£o de resposta com Gemini


## ğŸ BÃ´nus: Chat com HistÃ³rico Conversacional

### ğŸ’¬ Funcionalidade Extra
AlÃ©m do chat bÃ¡sico, implementei um **chat com memÃ³ria conversacional**:

```bash
python3 src/chat_with_history.py
```

### âœ¨ Recursos Adicionais
- **MemÃ³ria de conversa**: MantÃ©m contexto entre perguntas
- **SessÃµes independentes**: MÃºltiplos usuÃ¡rios simultÃ¢neos
- **Comandos especiais**:
  - `historico` - Ver histÃ³rico da conversa
  - `limpar` - Limpar memÃ³ria da sessÃ£o
  - `sair` - Encerrar chat
- **Interface aprimorada**: Emojis e formataÃ§Ã£o visual

### ğŸ”„ Exemplo de Uso Conversacional
```
ğŸ¤– Chat com HistÃ³rico - Sistema de Busca SemÃ¢ntica
==================================================
ğŸ” Validando variÃ¡veis de ambiente...
ğŸ“‹ VariÃ¡veis configuradas:
  âœ… GOOGLE_API_KEY = AIzaSyAU...
  âœ… DATABASE_URL = postgresql+psycopg://postgres:postgres@localhost:5432/rag
  âœ… PG_VECTOR_COLLECTION_NAME = pdf_chunks
  âœ… PDF_PATH = document.pdf
âœ… Todas as variÃ¡veis de ambiente estÃ£o configuradas!

Comandos especiais:
- 'sair', 'exit', 'quit': Encerrar chat
- 'limpar', 'clear': Limpar histÃ³rico
- 'historico', 'history': Ver histÃ³rico

FAÃ‡A SUA PERGUNTA: me fala sobre a primeira empresa no contexto
RESPOSTA DO MODELO: A primeira empresa no contexto Ã© a Ã‰pico ImobiliÃ¡ria ServiÃ§os, com receita de R$ 12.800.650,98 e fundada em 1970.

FAÃ‡A SUA PERGUNTA: qual Ã© o nome dela ?
RESPOSTA DO MODELO: Ã‰pico ImobiliÃ¡ria ServiÃ§os.

FAÃ‡A SUA PERGUNTA: e da  Alfa ImobiliÃ¡ria S.A ?
RESPOSTA DO MODELO: A Alfa ImobiliÃ¡ria S.A. teve um faturamento de R$ 666.804.293,08 e foi fundada em 2012.

FAÃ‡A SUA PERGUNTA: historico

HistÃ³rico da conversa:
1. VOCÃŠ: me fala sobre a primeira empresa no contexto
2. ASSISTENTE: A primeira empresa no contexto Ã© a Ã‰pico ImobiliÃ¡ria ServiÃ§os, com receita de R$ 12.800.650,98 e fun...
3. VOCÃŠ: qual Ã© o nome dela ?
4. ASSISTENTE: Ã‰pico ImobiliÃ¡ria ServiÃ§os.
5. VOCÃŠ: e da  Alfa ImobiliÃ¡ria S.A ?
6. ASSISTENTE: A Alfa ImobiliÃ¡ria S.A. teve um faturamento de R$ 666.804.293,08 e foi fundada em 2012.

```

### ğŸ—ï¸ Arquitetura Conversacional
- **`ConversationalSearchService`**: Classe principal com memÃ³ria
- **`InMemoryChatMessageHistory`**: Armazenamento de sessÃµes
- **Message Trimming**: MantÃ©m Ãºltimas 10 mensagens
- **Context Integration**: Combina busca semÃ¢ntica + histÃ³rico

## ğŸ“Š Status do Projeto

âœ… **Funcionalidades Implementadas**:
- IngestÃ£o de PDF com chunking
- Armazenamento vetorial PostgreSQL + pgVector
- Busca semÃ¢ntica com k=10
- Interface CLI interativa
- ValidaÃ§Ã£o de variÃ¡veis de ambiente
- Tipagem Python
- Classe SearchService organizada
- **ğŸ Chat com histÃ³rico conversacional**

âœ… **EvidÃªncias de testes**:
- Docker Compose com PostgreSQL
- IngestÃ£o completa (67 chunks processados)
- Chat respondendo perguntas sobre o documento
- RejeiÃ§Ã£o de perguntas fora do contexto
- **Chat conversacional mantendo contexto**

---
**ğŸ“ Desenvolvido para o desafio MBA Engenharia de Software com IA - Full Cycle**